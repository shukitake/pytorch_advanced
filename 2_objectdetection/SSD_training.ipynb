{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# パッケージのimport\n",
    "import os.path as osp\n",
    "import random\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシードを設定\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用デバイス：\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import make_datapath_list, VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n",
    "\n",
    "#ファイルパスのリストを取得\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath)\n",
    "\n",
    "#Datasetを作成\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "color_mean = (104, 117, 123) # (BGR)の色の平均値\n",
    "input_size = 300 # 画像のinputサイズを300×300にする\n",
    "\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\",\n",
    "    transform=DataTransform(input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\",\n",
    "    transform=DataTransform(input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "#Dataloaderを作成\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=od_collate_fn)\n",
    "\n",
    "#辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m net \u001b[39m=\u001b[39m SSD(phase\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, cfg\u001b[39m=\u001b[39mssd_cfg)\n\u001b[1;32m     18\u001b[0m \u001b[39m# SSDの学習済みの重みを設定\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m#ssdのvggの重みをロード\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m vgg_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m./weights/ssd300_mAP_77.43_v2.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     21\u001b[0m net\u001b[39m.\u001b[39mvgg\u001b[39m.\u001b[39mload_state_dict(vgg_weights)\n\u001b[1;32m     23\u001b[0m \u001b[39m#ssdのその他の重みはHeの初期値で初期化\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py38/lib/python3.8/site-packages/torch/serialization.py:713\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[1;32m    712\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> 713\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m/opt/conda/envs/py38/lib/python3.8/site-packages/torch/serialization.py:930\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    928\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m    929\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m--> 930\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    932\u001b[0m deserialized_storage_keys \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mload(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m    934\u001b[0m offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell() \u001b[39mif\u001b[39;00m f_should_read_directly \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py38/lib/python3.8/site-packages/torch/serialization.py:876\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    872\u001b[0m     obj\u001b[39m.\u001b[39m_torch_load_uninitialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    873\u001b[0m     \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    874\u001b[0m     \u001b[39m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m    875\u001b[0m     deserialized_objects[root_key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39m_TypedStorage(\n\u001b[0;32m--> 876\u001b[0m         wrap_storage\u001b[39m=\u001b[39mrestore_location(obj, location),\n\u001b[1;32m    877\u001b[0m         dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    879\u001b[0m typed_storage \u001b[39m=\u001b[39m deserialized_objects[root_key]\n\u001b[1;32m    880\u001b[0m \u001b[39mif\u001b[39;00m view_metadata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/py38/lib/python3.8/site-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    174\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 175\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    176\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/envs/py38/lib/python3.8/site-packages/torch/serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    151\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 152\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    153\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    154\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m/opt/conda/envs/py38/lib/python3.8/site-packages/torch/serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    140\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "from utils.ssd_model import SSD\n",
    "\n",
    "# SSD300の設定\n",
    "ssd_cfg = {\n",
    "    'num_classes': 21, # 背景クラスを含めた合計クラス数\n",
    "    'input_size': 300, # 画像の入力サイズ\n",
    "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4], # 出力するDBoxのアスペクト比の種類\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1], # 各sourceの画像サイズ\n",
    "    'steps': [8, 16, 32, 64, 100, 300], # DBoxの大きさを決める\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264], # 小さい正方形のDBoxの大きさ\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315], # 大きい正方形のDBoxの大きさ\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]], # DBoxのアスペクト比\n",
    "}\n",
    "\n",
    "# SSDネットワークモデルの作成\n",
    "net = SSD(phase=\"train\", cfg=ssd_cfg)\n",
    "\n",
    "# SSDの学習済みの重みを設定\n",
    "#ssdのvggの重みをロード\n",
    "vgg_weights = torch.load(\"./weights/ssd300_mAP_77.43_v2.pth\")\n",
    "net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "#ssdのその他の重みはHeの初期値で初期化\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:  #バイアス項がある場合\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "#Heの初期値で初期化\n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)\n",
    "\n",
    "#GPUが使えるか確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用デバイス：\", device)\n",
    "\n",
    "print(\"ネットワーク設定完了：学習済みの重みをロードしました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import MultiBoxLoss\n",
    "\n",
    "#損失関数の設定\n",
    "criterion = MultiBoxLoss(jaccard_thresh=0.5, neg_pos=3, device=device)\n",
    "\n",
    "#最適化手法の設定\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルを学習させる関数を作成\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    #GPUが使えるか確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "\n",
    "    #ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    #ネットワークがある程度固定であれば高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    #イテレーションカウンターをセット\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0 #epochの損失和\n",
    "    epoch_val_loss = 0.0 #epochの損失和\n",
    "    logs = [] #学習過程を記録\n",
    "\n",
    "    #epochのループ\n",
    "    for epoch in range(num_epochs+1):\n",
    "\n",
    "        #開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print(\"-------------\")\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
    "        print(\"-------------\")\n",
    "\n",
    "        #epochごとの学習と検証のループ\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                net.train() #訓練モードに設定\n",
    "                print(\"（train）\")\n",
    "            else:\n",
    "                if (epoch+1) % 10 == 0: #10エポックに1度検証を行う\n",
    "                    net.eval() #検証モードに設定\n",
    "                    print(\"-------------\")\n",
    "                    print(\"（val）\")\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            #データローダーからminibatchずつ取り出すループ\n",
    "            for images, targets in dataloaders_dict[phase]:\n",
    "                #GPUが使えるならGPUにデータを送る\n",
    "                images = images.to(device) #画像\n",
    "                targets = [ann.to(device) for ann in targets] #リストの各要素のテンソルをGPUへ\n",
    "\n",
    "                #optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    #順伝播（forward）計算\n",
    "                    outputs = net(images)\n",
    "\n",
    "                    #損失の計算\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "                    #訓練時はバックプロパゲーション\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()　#勾配の計算\n",
    "                    \n",
    "                        #勾配が大きくなりすぎるのを防ぐ\n",
    "                        nn.utils.clip_grad_value_(net.parameters(), clip_value=2.0)\n",
    "\n",
    "                        optimizer.step() #パラメータの更新\n",
    "\n",
    "                        if (iteration % 10) == 0: #10iterに1度、lossを表示\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print(\"イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.\".format(iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                    #結果の計算\n",
    "                    epoch_train_loss += loss.item() \n",
    "                    iteration += 1\n",
    "            \n",
    "            #epochのphaseごとのloss\n",
    "            t_epoch_finish = time.time()\n",
    "            print(\"--------------------\")\n",
    "            print(\"epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}\".format(epoch+1, epoch_train_loss, epoch_val_loss))\n",
    "            print(\"timer:  {:.4f} sec.\".format(t_epoch_finish - t_epoch_start))\n",
    "            t_epoch_start = time.time()\n",
    "\n",
    "            #ログを保存\n",
    "            log_epoch = {\"epoch\": epoch+1, \"train_loss\": epoch_train_loss, \"val_loss\": epoch_val_loss}\n",
    "            logs.append(log_epoch)\n",
    "            df = pd.DataFrame(logs)\n",
    "            df.to_csv(\"log_output.csv\") #ログをcsvへ保存\n",
    "\n",
    "            epoch_train_loss = 0.0 #epochの損失和\n",
    "            epoch_val_loss = 0.0 #epochの損失和\n",
    "\n",
    "            #ネットワークを保存\n",
    "            if (epoch+1) % 10 == 0:\n",
    "                torch.save(net.state_dict(), \"weights/ssd300_\" + str(epoch+1) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習・検証を実行する\n",
    "num_epochs=50\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
