{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3～3.6 ネットワークモデルの作成\n",
    "\n",
    "- 本ファイルでは、PSPNetのネットワークモデルと順伝搬forward関数を作成します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 学習目標\n",
    "\n",
    "1.\tPSPNetのネットワーク構造をモジュール単位で理解する\n",
    "2.\tPSPNetを構成する各モジュールの役割を理解する\n",
    "3.\tPSPNetのネットワーククラスの実装を理解する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 学習目標\n",
    "\n",
    "1.\tFeatureモジュールのサブネットワーク構成を理解する\n",
    "2.\tサブネットワークFeatureMap_convolution を実装できるようになる\n",
    "3.\tResidual Blockを理解する\n",
    "4.\tDilated Convolutionを理解する\n",
    "5.\tサブネットワークbottleNeckPSPとbottleNeckIdentifyPSPを実装できるようになる\n",
    "6.\tFeatureモジュールを実装できるようになる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 学習目標\n",
    "\n",
    "1.\tPyramid Poolingモジュールのサブネットワーク構成を理解する\n",
    "2.\tPyramid Poolingモジュールのマルチスケール処理の実現方法を理解する\n",
    "3.\tPyramid Poolingモジュールを実装できるようになる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 学習目標\n",
    "\n",
    "1.\tDecoderモジュールのサブネットワーク構成を理解する\n",
    "2.\tDecoder モジュールを実装できるようになる\n",
    "3.\tAuxLossモジュールのサブネットワーク構成を理解する\n",
    "4.\tAuxLossモジュールを実装できるようになる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 事前準備\n",
    "\n",
    "\n",
    "とくになし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# パッケージのimport\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 PSPNetのネットワーク構造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(PSPNet, self).__init__()\n",
    "\n",
    "        # パラメータ設定\n",
    "        block_config = [3, 4, 6, 3]  # resnet50\n",
    "        img_size = 475\n",
    "        img_size_8 = 60  # img_sizeの1/8に\n",
    "\n",
    "        # 4つのモジュールを構成するサブネットワークの用意\n",
    "        self.feature_conv = FeatureMap_convolution()\n",
    "        self.feature_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n",
    "        self.feature_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n",
    "        self.feature_dilated_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n",
    "        self.feature_dilated_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n",
    "\n",
    "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[\n",
    "            6, 3, 2, 1], height=img_size_8, width=img_size_8)\n",
    "\n",
    "        self.decode_feature = DecodePSPFeature(\n",
    "            height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "        self.aux = AuxiliaryPSPlayers(\n",
    "            in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_conv(x)\n",
    "        x = self.feature_res_1(x)\n",
    "        x = self.feature_res_2(x)\n",
    "        x = self.feature_dilated_res_1(x)\n",
    "\n",
    "        output_aux = self.aux(x)  # Featureモジュールの途中をAuxモジュールへ\n",
    "\n",
    "        x = self.feature_dilated_res_2(x)\n",
    "\n",
    "        x = self.pyramid_pooling(x)\n",
    "        output = self.decode_feature(x)\n",
    "\n",
    "        return (output, output_aux)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Featureモジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNormRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # inplase設定で入力を保存せずに出力を計算し、メモリ削減する\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        outputs = self.relu(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMap_convolution(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''構成するネットワークを用意'''\n",
    "        super(FeatureMap_convolution, self).__init__()\n",
    "\n",
    "        # 畳み込み層1\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 3, 64, 3, 2, 1, 1, False\n",
    "        self.cbnr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # 畳み込み層2\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 64, 3, 1, 1, 1, False\n",
    "        self.cbnr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # 畳み込み層3\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 128, 3, 1, 1, 1, False\n",
    "        self.cbnr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # MaxPooling層\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbnr_1(x)\n",
    "        x = self.cbnr_2(x)\n",
    "        x = self.cbnr_3(x)\n",
    "        outputs = self.maxpool(x)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockPSP(nn.Sequential):\n",
    "    def __init__(self, n_blocks, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(ResidualBlockPSP, self).__init__()\n",
    "\n",
    "        # bottleNeckPSPの用意\n",
    "        self.add_module(\n",
    "            \"block1\",\n",
    "            bottleNeckPSP(in_channels, mid_channels,\n",
    "                          out_channels, stride, dilation)\n",
    "        )\n",
    "\n",
    "        # bottleNeckIdentifyPSPの繰り返しの用意\n",
    "        for i in range(n_blocks - 1):\n",
    "            self.add_module(\n",
    "                \"block\" + str(i+2),\n",
    "                bottleNeckIdentifyPSP(\n",
    "                    out_channels, mid_channels, stride, dilation)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNorm, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        outputs = self.batchnorm(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(bottleNeckPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        # スキップ結合\n",
    "        self.cb_residual = conv2DBatchNorm(\n",
    "            in_channels, out_channels, kernel_size=1, stride=stride, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = self.cb_residual(x)\n",
    "        return self.relu(conv + residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckIdentifyPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, stride, dilation):\n",
    "        super(bottleNeckIdentifyPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, in_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = x\n",
    "        return self.relu(conv + residual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 Pyramid Poolingモジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_channels, pool_sizes, height, width):\n",
    "        super(PyramidPooling, self).__init__()\n",
    "\n",
    "        # forwardで使用する画像サイズ\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        # 各畳み込み層の出力チャネル数\n",
    "        out_channels = int(in_channels / len(pool_sizes))\n",
    "\n",
    "        # 各畳み込み層を作成\n",
    "        # この実装方法は愚直すぎてfor文で書きたいところですが、分かりやすさを優先しています\n",
    "        # pool_sizes: [6, 3, 2, 1]\n",
    "        self.avpool_1 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_2 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[1])\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_3 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[2])\n",
    "        self.cbr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_4 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[3])\n",
    "        self.cbr_4 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.cbr_1(self.avpool_1(x))\n",
    "        out1 = F.interpolate(out1, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out2 = self.cbr_2(self.avpool_2(x))\n",
    "        out2 = F.interpolate(out2, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out3 = self.cbr_3(self.avpool_3(x))\n",
    "        out3 = F.interpolate(out3, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out4 = self.cbr_4(self.avpool_4(x))\n",
    "        out4 = F.interpolate(out4, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        # 最終的に結合させる、dim=1でチャネル数の次元で結合\n",
    "        output = torch.cat([x, out1, out2, out3, out4], dim=1)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Decoder、AuxLossモジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodePSPFeature(nn.Module):\n",
    "    def __init__(self, height, width, n_classes):\n",
    "        super(DecodePSPFeature, self).__init__()\n",
    "\n",
    "        # forwardで使用する画像サイズ\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNormRelu(\n",
    "            in_channels=4096, out_channels=512, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxiliaryPSPlayers(nn.Module):\n",
    "    def __init__(self, in_channels, height, width, n_classes):\n",
    "        super(AuxiliaryPSPlayers, self).__init__()\n",
    "\n",
    "        # forwardで使用する画像サイズ\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNormRelu(\n",
    "            in_channels=in_channels, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSPNet(\n",
       "  (feature_conv): FeatureMap_convolution(\n",
       "    (cbnr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (feature_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block5): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block6): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pyramid_pooling): PyramidPooling(\n",
       "    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n",
       "    (cbr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n",
       "    (cbr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n",
       "    (cbr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n",
       "    (cbr_4): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decode_feature): DecodePSPFeature(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux): AuxiliaryPSPlayers(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの定義\n",
    "net = PSPNet(n_classes=21)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[ 0.0096,  0.0377,  0.0658,  ...,  0.2810,  0.2801,  0.2792],\n",
      "          [-0.0747, -0.0427, -0.0107,  ...,  0.2449,  0.2426,  0.2404],\n",
      "          [-0.1590, -0.1230, -0.0871,  ...,  0.2088,  0.2052,  0.2016],\n",
      "          ...,\n",
      "          [-0.3685, -0.3593, -0.3500,  ..., -0.4909, -0.5490, -0.6071],\n",
      "          [-0.3389, -0.3405, -0.3422,  ..., -0.5135, -0.5735, -0.6334],\n",
      "          [-0.3093, -0.3218, -0.3343,  ..., -0.5362, -0.5980, -0.6597]],\n",
      "\n",
      "         [[-0.4217, -0.4276, -0.4334,  ..., -0.9035, -0.9417, -0.9799],\n",
      "          [-0.3599, -0.3736, -0.3873,  ..., -0.8700, -0.9126, -0.9551],\n",
      "          [-0.2981, -0.3197, -0.3412,  ..., -0.8366, -0.8834, -0.9303],\n",
      "          ...,\n",
      "          [-0.2441, -0.2389, -0.2338,  ..., -0.6979, -0.7562, -0.8144],\n",
      "          [-0.2128, -0.2089, -0.2050,  ..., -0.7314, -0.7972, -0.8629],\n",
      "          [-0.1815, -0.1788, -0.1762,  ..., -0.7650, -0.8382, -0.9115]],\n",
      "\n",
      "         [[-0.3753, -0.4455, -0.5157,  ..., -0.4467, -0.4466, -0.4464],\n",
      "          [-0.3713, -0.4281, -0.4849,  ..., -0.3950, -0.3943, -0.3937],\n",
      "          [-0.3673, -0.4107, -0.4540,  ..., -0.3432, -0.3421, -0.3409],\n",
      "          ...,\n",
      "          [-0.5788, -0.5201, -0.4614,  ...,  0.1382,  0.1101,  0.0821],\n",
      "          [-0.6174, -0.5619, -0.5064,  ...,  0.1697,  0.1551,  0.1405],\n",
      "          [-0.6560, -0.6037, -0.5514,  ...,  0.2012,  0.2000,  0.1989]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3275,  0.2397,  0.1519,  ..., -0.0223,  0.0450,  0.1122],\n",
      "          [ 0.2871,  0.2120,  0.1369,  ..., -0.0035,  0.0571,  0.1178],\n",
      "          [ 0.2467,  0.1843,  0.1219,  ...,  0.0154,  0.0693,  0.1233],\n",
      "          ...,\n",
      "          [ 0.1094,  0.1065,  0.1037,  ...,  0.4232,  0.4279,  0.4326],\n",
      "          [ 0.0973,  0.0906,  0.0839,  ...,  0.4078,  0.4137,  0.4196],\n",
      "          [ 0.0852,  0.0746,  0.0641,  ...,  0.3924,  0.3995,  0.4066]],\n",
      "\n",
      "         [[ 0.0329,  0.0119, -0.0091,  ..., -0.2675, -0.2828, -0.2980],\n",
      "          [ 0.0620,  0.0423,  0.0226,  ..., -0.2753, -0.2898, -0.3044],\n",
      "          [ 0.0911,  0.0726,  0.0542,  ..., -0.2831, -0.2969, -0.3108],\n",
      "          ...,\n",
      "          [-0.1480, -0.1336, -0.1192,  ..., -0.6230, -0.6550, -0.6870],\n",
      "          [-0.2245, -0.2088, -0.1932,  ..., -0.6202, -0.6369, -0.6537],\n",
      "          [-0.3009, -0.2841, -0.2673,  ..., -0.6174, -0.6188, -0.6203]],\n",
      "\n",
      "         [[-0.1202, -0.0908, -0.0613,  ..., -0.6348, -0.6629, -0.6910],\n",
      "          [-0.1075, -0.0814, -0.0552,  ..., -0.5603, -0.5880, -0.6156],\n",
      "          [-0.0948, -0.0719, -0.0491,  ..., -0.4859, -0.5131, -0.5403],\n",
      "          ...,\n",
      "          [ 0.0184, -0.0046, -0.0275,  ..., -0.4072, -0.3752, -0.3432],\n",
      "          [ 0.0462,  0.0241,  0.0019,  ..., -0.4704, -0.4453, -0.4202],\n",
      "          [ 0.0741,  0.0528,  0.0314,  ..., -0.5336, -0.5154, -0.4972]]],\n",
      "\n",
      "\n",
      "        [[[-0.0055,  0.0159,  0.0372,  ...,  0.4720,  0.4954,  0.5187],\n",
      "          [-0.0087,  0.0126,  0.0339,  ...,  0.3922,  0.3984,  0.4047],\n",
      "          [-0.0118,  0.0094,  0.0307,  ...,  0.3123,  0.3015,  0.2907],\n",
      "          ...,\n",
      "          [ 0.2369,  0.1889,  0.1409,  ..., -0.4137, -0.4359, -0.4581],\n",
      "          [ 0.2937,  0.2425,  0.1912,  ..., -0.3857, -0.3958, -0.4059],\n",
      "          [ 0.3505,  0.2960,  0.2416,  ..., -0.3576, -0.3557, -0.3537]],\n",
      "\n",
      "         [[-0.2427, -0.2710, -0.2993,  ..., -0.5435, -0.5839, -0.6243],\n",
      "          [-0.2833, -0.3047, -0.3260,  ..., -0.5452, -0.5785, -0.6118],\n",
      "          [-0.3239, -0.3383, -0.3527,  ..., -0.5469, -0.5731, -0.5993],\n",
      "          ...,\n",
      "          [-0.1878, -0.2367, -0.2857,  ..., -0.5355, -0.5106, -0.4858],\n",
      "          [-0.1537, -0.2057, -0.2576,  ..., -0.5565, -0.5222, -0.4878],\n",
      "          [-0.1196, -0.1746, -0.2296,  ..., -0.5776, -0.5337, -0.4898]],\n",
      "\n",
      "         [[-0.3947, -0.3490, -0.3033,  ..., -0.1891, -0.1628, -0.1365],\n",
      "          [-0.3446, -0.3121, -0.2796,  ..., -0.2396, -0.2234, -0.2072],\n",
      "          [-0.2945, -0.2752, -0.2559,  ..., -0.2901, -0.2840, -0.2779],\n",
      "          ...,\n",
      "          [-0.3497, -0.3988, -0.4479,  ..., -0.2982, -0.3066, -0.3151],\n",
      "          [-0.2818, -0.3447, -0.4075,  ..., -0.2926, -0.3068, -0.3209],\n",
      "          [-0.2139, -0.2906, -0.3672,  ..., -0.2870, -0.3069, -0.3267]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2163, -0.2061, -0.1959,  ..., -0.4691, -0.5071, -0.5450],\n",
      "          [-0.2005, -0.1949, -0.1894,  ..., -0.4263, -0.4532, -0.4802],\n",
      "          [-0.1846, -0.1837, -0.1829,  ..., -0.3834, -0.3994, -0.4154],\n",
      "          ...,\n",
      "          [-0.0703, -0.0470, -0.0236,  ..., -0.0847, -0.0854, -0.0861],\n",
      "          [-0.0998, -0.0805, -0.0612,  ..., -0.1035, -0.1038, -0.1041],\n",
      "          [-0.1294, -0.1140, -0.0987,  ..., -0.1223, -0.1222, -0.1220]],\n",
      "\n",
      "         [[-0.4357, -0.4144, -0.3930,  ..., -0.3271, -0.3328, -0.3385],\n",
      "          [-0.3912, -0.3683, -0.3453,  ..., -0.3121, -0.3208, -0.3295],\n",
      "          [-0.3467, -0.3222, -0.2977,  ..., -0.2971, -0.3088, -0.3205],\n",
      "          ...,\n",
      "          [-0.2221, -0.1913, -0.1606,  ..., -0.5490, -0.5861, -0.6232],\n",
      "          [-0.2041, -0.1773, -0.1505,  ..., -0.5785, -0.6044, -0.6302],\n",
      "          [-0.1862, -0.1633, -0.1405,  ..., -0.6080, -0.6227, -0.6373]],\n",
      "\n",
      "         [[-0.0225, -0.0365, -0.0506,  ...,  0.2805,  0.2383,  0.1961],\n",
      "          [-0.0165, -0.0247, -0.0328,  ...,  0.3172,  0.2834,  0.2497],\n",
      "          [-0.0106, -0.0128, -0.0149,  ...,  0.3540,  0.3286,  0.3033],\n",
      "          ...,\n",
      "          [-0.2519, -0.1941, -0.1364,  ...,  0.0417,  0.0891,  0.1366],\n",
      "          [-0.2605, -0.1978, -0.1351,  ...,  0.0690,  0.1211,  0.1732],\n",
      "          [-0.2690, -0.2015, -0.1339,  ...,  0.0962,  0.1530,  0.2098]]]],\n",
      "       grad_fn=<UpsampleBilinear2DBackward1>), tensor([[[[-2.0145e-01, -1.7113e-01, -1.4081e-01,  ...,  1.0065e-01,\n",
      "            9.6646e-02,  9.2648e-02],\n",
      "          [-1.3620e-01, -1.0880e-01, -8.1400e-02,  ...,  6.6198e-02,\n",
      "            5.6366e-02,  4.6533e-02],\n",
      "          [-7.0954e-02, -4.6470e-02, -2.1986e-02,  ...,  3.1752e-02,\n",
      "            1.6085e-02,  4.1811e-04],\n",
      "          ...,\n",
      "          [-2.0680e-01, -1.5285e-01, -9.8902e-02,  ...,  6.2699e-02,\n",
      "            5.1762e-02,  4.0826e-02],\n",
      "          [-1.8605e-01, -1.3106e-01, -7.6080e-02,  ...,  6.4864e-02,\n",
      "            4.7739e-02,  3.0613e-02],\n",
      "          [-1.6529e-01, -1.0927e-01, -5.3258e-02,  ...,  6.7030e-02,\n",
      "            4.3715e-02,  2.0399e-02]],\n",
      "\n",
      "         [[-2.4471e-01, -2.6900e-01, -2.9330e-01,  ..., -6.0998e-01,\n",
      "           -5.7088e-01, -5.3177e-01],\n",
      "          [-2.5412e-01, -2.7049e-01, -2.8687e-01,  ..., -5.8213e-01,\n",
      "           -5.4147e-01, -5.0082e-01],\n",
      "          [-2.6352e-01, -2.7198e-01, -2.8044e-01,  ..., -5.5427e-01,\n",
      "           -5.1207e-01, -4.6987e-01],\n",
      "          ...,\n",
      "          [-3.5931e-01, -3.6280e-01, -3.6629e-01,  ..., -4.4649e-01,\n",
      "           -4.7042e-01, -4.9435e-01],\n",
      "          [-3.2470e-01, -3.3001e-01, -3.3533e-01,  ..., -4.2125e-01,\n",
      "           -4.3904e-01, -4.5684e-01],\n",
      "          [-2.9008e-01, -2.9723e-01, -3.0438e-01,  ..., -3.9601e-01,\n",
      "           -4.0766e-01, -4.1932e-01]],\n",
      "\n",
      "         [[-3.1258e-01, -3.9744e-01, -4.8230e-01,  ..., -4.9520e-01,\n",
      "           -4.1807e-01, -3.4094e-01],\n",
      "          [-3.3557e-01, -4.0515e-01, -4.7474e-01,  ..., -4.9860e-01,\n",
      "           -4.2925e-01, -3.5990e-01],\n",
      "          [-3.5855e-01, -4.1287e-01, -4.6718e-01,  ..., -5.0199e-01,\n",
      "           -4.4042e-01, -3.7885e-01],\n",
      "          ...,\n",
      "          [-4.3798e-01, -4.4833e-01, -4.5867e-01,  ..., -6.1231e-01,\n",
      "           -6.1279e-01, -6.1327e-01],\n",
      "          [-4.5313e-01, -4.5191e-01, -4.5069e-01,  ..., -5.6412e-01,\n",
      "           -5.6618e-01, -5.6825e-01],\n",
      "          [-4.6827e-01, -4.5549e-01, -4.4270e-01,  ..., -5.1594e-01,\n",
      "           -5.1958e-01, -5.2322e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.4532e-02,  1.0697e-01,  1.6940e-01,  ...,  3.1610e-01,\n",
      "            4.0891e-01,  5.0172e-01],\n",
      "          [ 7.5039e-02,  1.3164e-01,  1.8824e-01,  ...,  2.8795e-01,\n",
      "            3.7009e-01,  4.5224e-01],\n",
      "          [ 1.0554e-01,  1.5631e-01,  2.0708e-01,  ...,  2.5980e-01,\n",
      "            3.3128e-01,  4.0276e-01],\n",
      "          ...,\n",
      "          [ 3.0866e-01,  3.3807e-01,  3.6748e-01,  ...,  3.4179e-01,\n",
      "            3.3745e-01,  3.3311e-01],\n",
      "          [ 3.0249e-01,  3.3074e-01,  3.5899e-01,  ...,  3.9042e-01,\n",
      "            3.7065e-01,  3.5088e-01],\n",
      "          [ 2.9633e-01,  3.2341e-01,  3.5050e-01,  ...,  4.3904e-01,\n",
      "            4.0384e-01,  3.6864e-01]],\n",
      "\n",
      "         [[-1.0097e-01, -1.4179e-01, -1.8261e-01,  ..., -3.7826e-01,\n",
      "           -3.9249e-01, -4.0673e-01],\n",
      "          [-7.6802e-02, -1.2036e-01, -1.6391e-01,  ..., -3.7082e-01,\n",
      "           -3.8458e-01, -3.9834e-01],\n",
      "          [-5.2632e-02, -9.8920e-02, -1.4521e-01,  ..., -3.6338e-01,\n",
      "           -3.7666e-01, -3.8995e-01],\n",
      "          ...,\n",
      "          [-7.6355e-02, -1.0201e-01, -1.2766e-01,  ..., -5.0255e-01,\n",
      "           -5.2137e-01, -5.4019e-01],\n",
      "          [-9.7058e-02, -1.1883e-01, -1.4060e-01,  ..., -5.0510e-01,\n",
      "           -5.1765e-01, -5.3019e-01],\n",
      "          [-1.1776e-01, -1.3565e-01, -1.5354e-01,  ..., -5.0766e-01,\n",
      "           -5.1393e-01, -5.2019e-01]],\n",
      "\n",
      "         [[-3.5150e-01, -3.3929e-01, -3.2709e-01,  ..., -1.6767e-01,\n",
      "           -1.4415e-01, -1.2063e-01],\n",
      "          [-3.0239e-01, -2.9360e-01, -2.8481e-01,  ..., -1.1604e-01,\n",
      "           -9.6452e-02, -7.6865e-02],\n",
      "          [-2.5328e-01, -2.4791e-01, -2.4254e-01,  ..., -6.4408e-02,\n",
      "           -4.8755e-02, -3.3101e-02],\n",
      "          ...,\n",
      "          [-3.8039e-01, -3.5376e-01, -3.2713e-01,  ...,  1.0478e-01,\n",
      "            9.5829e-02,  8.6875e-02],\n",
      "          [-4.1249e-01, -3.7607e-01, -3.3965e-01,  ...,  1.4276e-01,\n",
      "            1.4111e-01,  1.3947e-01],\n",
      "          [-4.4459e-01, -3.9838e-01, -3.5218e-01,  ...,  1.8073e-01,\n",
      "            1.8640e-01,  1.9206e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0790e-01,  2.0585e-01,  2.0381e-01,  ..., -7.8783e-02,\n",
      "           -1.4442e-01, -2.1006e-01],\n",
      "          [ 2.4670e-01,  2.5137e-01,  2.5605e-01,  ..., -2.8887e-02,\n",
      "           -8.3082e-02, -1.3728e-01],\n",
      "          [ 2.8550e-01,  2.9689e-01,  3.0829e-01,  ...,  2.1010e-02,\n",
      "           -2.1739e-02, -6.4489e-02],\n",
      "          ...,\n",
      "          [ 1.1724e-01,  1.6412e-01,  2.1101e-01,  ...,  1.2177e-01,\n",
      "            8.9923e-02,  5.8077e-02],\n",
      "          [ 1.1961e-01,  1.5795e-01,  1.9629e-01,  ...,  1.5397e-01,\n",
      "            1.2705e-01,  1.0012e-01],\n",
      "          [ 1.2198e-01,  1.5178e-01,  1.8157e-01,  ...,  1.8617e-01,\n",
      "            1.6417e-01,  1.4217e-01]],\n",
      "\n",
      "         [[-3.0563e-01, -2.6955e-01, -2.3347e-01,  ..., -7.3564e-01,\n",
      "           -7.9879e-01, -8.6193e-01],\n",
      "          [-3.1277e-01, -2.7860e-01, -2.4443e-01,  ..., -6.7309e-01,\n",
      "           -7.2158e-01, -7.7006e-01],\n",
      "          [-3.1991e-01, -2.8765e-01, -2.5539e-01,  ..., -6.1054e-01,\n",
      "           -6.4436e-01, -6.7818e-01],\n",
      "          ...,\n",
      "          [-5.7142e-01, -5.5755e-01, -5.4369e-01,  ..., -6.0417e-01,\n",
      "           -5.9573e-01, -5.8728e-01],\n",
      "          [-6.3736e-01, -6.2157e-01, -6.0578e-01,  ..., -5.6849e-01,\n",
      "           -5.5087e-01, -5.3325e-01],\n",
      "          [-7.0331e-01, -6.8559e-01, -6.6788e-01,  ..., -5.3282e-01,\n",
      "           -5.0602e-01, -4.7921e-01]],\n",
      "\n",
      "         [[-2.8373e-01, -3.0947e-01, -3.3521e-01,  ..., -2.9419e-01,\n",
      "           -2.6989e-01, -2.4559e-01],\n",
      "          [-2.5996e-01, -2.8331e-01, -3.0665e-01,  ..., -2.7761e-01,\n",
      "           -2.5015e-01, -2.2269e-01],\n",
      "          [-2.3620e-01, -2.5715e-01, -2.7809e-01,  ..., -2.6103e-01,\n",
      "           -2.3041e-01, -1.9979e-01],\n",
      "          ...,\n",
      "          [-4.4864e-01, -4.4651e-01, -4.4439e-01,  ..., -3.4295e-01,\n",
      "           -2.8839e-01, -2.3384e-01],\n",
      "          [-4.7879e-01, -4.7082e-01, -4.6285e-01,  ..., -3.1081e-01,\n",
      "           -2.6081e-01, -2.1080e-01],\n",
      "          [-5.0894e-01, -4.9512e-01, -4.8131e-01,  ..., -2.7868e-01,\n",
      "           -2.3322e-01, -1.8776e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.3724e-02,  1.0717e-01,  1.5062e-01,  ...,  1.9632e-01,\n",
      "            1.8628e-01,  1.7624e-01],\n",
      "          [ 1.1990e-01,  1.6039e-01,  2.0087e-01,  ...,  2.1588e-01,\n",
      "            2.1829e-01,  2.2071e-01],\n",
      "          [ 1.7608e-01,  2.1360e-01,  2.5113e-01,  ...,  2.3544e-01,\n",
      "            2.5031e-01,  2.6518e-01],\n",
      "          ...,\n",
      "          [ 4.6235e-01,  4.8719e-01,  5.1202e-01,  ...,  3.7450e-01,\n",
      "            3.9485e-01,  4.1521e-01],\n",
      "          [ 4.2879e-01,  4.6149e-01,  4.9419e-01,  ...,  3.9812e-01,\n",
      "            4.1590e-01,  4.3367e-01],\n",
      "          [ 3.9522e-01,  4.3579e-01,  4.7636e-01,  ...,  4.2175e-01,\n",
      "            4.3694e-01,  4.5213e-01]],\n",
      "\n",
      "         [[-5.0864e-02, -5.4968e-02, -5.9073e-02,  ..., -9.4994e-02,\n",
      "           -2.4512e-02,  4.5970e-02],\n",
      "          [-6.4081e-02, -6.9413e-02, -7.4744e-02,  ..., -1.1278e-01,\n",
      "           -5.0913e-02,  1.0953e-02],\n",
      "          [-7.7298e-02, -8.3857e-02, -9.0416e-02,  ..., -1.3056e-01,\n",
      "           -7.7313e-02, -2.4063e-02],\n",
      "          ...,\n",
      "          [ 8.6849e-02,  3.3756e-02, -1.9338e-02,  ..., -2.8706e-01,\n",
      "           -3.1254e-01, -3.3803e-01],\n",
      "          [ 1.1410e-01,  6.7000e-02,  1.9903e-02,  ..., -2.3625e-01,\n",
      "           -2.5637e-01, -2.7649e-01],\n",
      "          [ 1.4135e-01,  1.0024e-01,  5.9143e-02,  ..., -1.8545e-01,\n",
      "           -2.0020e-01, -2.1495e-01]],\n",
      "\n",
      "         [[-2.2982e-01, -2.2593e-01, -2.2203e-01,  ..., -7.2900e-02,\n",
      "           -1.1481e-01, -1.5672e-01],\n",
      "          [-2.3126e-01, -2.2218e-01, -2.1309e-01,  ..., -2.4904e-02,\n",
      "           -5.5324e-02, -8.5744e-02],\n",
      "          [-2.3270e-01, -2.1843e-01, -2.0415e-01,  ...,  2.3092e-02,\n",
      "            4.1633e-03, -1.4765e-02],\n",
      "          ...,\n",
      "          [-3.3873e-01, -3.0672e-01, -2.7472e-01,  ...,  4.2650e-02,\n",
      "            2.1746e-02,  8.4263e-04],\n",
      "          [-3.6845e-01, -3.3718e-01, -3.0592e-01,  ...,  1.5273e-02,\n",
      "           -1.1494e-02, -3.8261e-02],\n",
      "          [-3.9817e-01, -3.6765e-01, -3.3712e-01,  ..., -1.2104e-02,\n",
      "           -4.4734e-02, -7.7364e-02]]]], grad_fn=<UpsampleBilinear2DBackward1>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    }
   ],
   "source": [
    "# ダミーデータの作成\n",
    "batch_size = 2\n",
    "dummy_img = torch.rand(batch_size, 3, 475, 475)\n",
    "\n",
    "# 計算\n",
    "outputs = net(dummy_img)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
