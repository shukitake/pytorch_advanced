{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3～3.6 ネットワークモデルの作成\n",
    "\n",
    "- 本ファイルでは、PSPNetのネットワークモデルと順伝搬forward関数を作成します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 学習目標\n",
    "\n",
    "1.\tPSPNetのネットワーク構造をモジュール単位で理解する\n",
    "2.\tPSPNetを構成する各モジュールの役割を理解する\n",
    "3.\tPSPNetのネットワーククラスの実装を理解する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 学習目標\n",
    "\n",
    "1.\tFeatureモジュールのサブネットワーク構成を理解する\n",
    "2.\tサブネットワークFeatureMap_convolution を実装できるようになる\n",
    "3.\tResidual Blockを理解する\n",
    "4.\tDilated Convolutionを理解する\n",
    "5.\tサブネットワークbottleNeckPSPとbottleNeckIdentifyPSPを実装できるようになる\n",
    "6.\tFeatureモジュールを実装できるようになる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 学習目標\n",
    "\n",
    "1.\tPyramid Poolingモジュールのサブネットワーク構成を理解する\n",
    "2.\tPyramid Poolingモジュールのマルチスケール処理の実現方法を理解する\n",
    "3.\tPyramid Poolingモジュールを実装できるようになる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 学習目標\n",
    "\n",
    "1.\tDecoderモジュールのサブネットワーク構成を理解する\n",
    "2.\tDecoder モジュールを実装できるようになる\n",
    "3.\tAuxLossモジュールのサブネットワーク構成を理解する\n",
    "4.\tAuxLossモジュールを実装できるようになる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 事前準備\n",
    "\n",
    "\n",
    "とくになし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 PSPNetのネットワーク構造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(PSPNet, self).__init__()\n",
    "\n",
    "        # パラメータ設定\n",
    "        block_config = [3, 4, 6, 3]  # resnet50\n",
    "        img_size = 475\n",
    "        img_size_8 = 60  # img_sizeの1/8に\n",
    "\n",
    "        # 4つのモジュールを構成するサブネットワークの用意\n",
    "        self.feature_conv = FeatureMap_convolution()\n",
    "        self.feature_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n",
    "        self.feature_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n",
    "        self.feature_dilated_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n",
    "        self.feature_dilated_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n",
    "\n",
    "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[\n",
    "            6, 3, 2, 1], height=img_size_8, width=img_size_8)\n",
    "\n",
    "        self.decode_feature = DecodePSPFeature(\n",
    "            height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "        self.aux = AuxiliaryPSPlayers(\n",
    "            in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_conv(x)\n",
    "        x = self.feature_res_1(x)\n",
    "        x = self.feature_res_2(x)\n",
    "        x = self.feature_dilated_res_1(x)\n",
    "\n",
    "        output_aux = self.aux(x)  # Featureモジュールの途中をAuxモジュールへ\n",
    "\n",
    "        x = self.feature_dilated_res_2(x)\n",
    "\n",
    "        x = self.pyramid_pooling(x)\n",
    "        output = self.decode_feature(x)\n",
    "\n",
    "        return (output, output_aux)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Featureモジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNormRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # inplase設定で入力を保存せずに出力を計算し、メモリ削減する\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        outputs = self.relu(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMap_convolution(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''構成するネットワークを用意'''\n",
    "        super(FeatureMap_convolution, self).__init__()\n",
    "\n",
    "        # 畳み込み層1\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 3, 64, 3, 2, 1, 1, False\n",
    "        self.cbnr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # 畳み込み層2\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 64, 3, 1, 1, 1, False\n",
    "        self.cbnr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # 畳み込み層3\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 128, 3, 1, 1, 1, False\n",
    "        self.cbnr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # MaxPooling層\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbnr_1(x)\n",
    "        x = self.cbnr_2(x)\n",
    "        x = self.cbnr_3(x)\n",
    "        outputs = self.maxpool(x)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockPSP(nn.Sequential):\n",
    "    def __init__(self, n_blocks, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(ResidualBlockPSP, self).__init__()\n",
    "\n",
    "        # bottleNeckPSPの用意\n",
    "        self.add_module(\n",
    "            \"block1\",\n",
    "            bottleNeckPSP(in_channels, mid_channels,\n",
    "                          out_channels, stride, dilation)\n",
    "        )\n",
    "\n",
    "        # bottleNeckIdentifyPSPの繰り返しの用意\n",
    "        for i in range(n_blocks - 1):\n",
    "            self.add_module(\n",
    "                \"block\" + str(i+2),\n",
    "                bottleNeckIdentifyPSP(\n",
    "                    out_channels, mid_channels, stride, dilation)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNorm, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        outputs = self.batchnorm(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(bottleNeckPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        # スキップ結合\n",
    "        self.cb_residual = conv2DBatchNorm(\n",
    "            in_channels, out_channels, kernel_size=1, stride=stride, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = self.cb_residual(x)\n",
    "        return self.relu(conv + residual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckIdentifyPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, stride, dilation):\n",
    "        super(bottleNeckIdentifyPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, in_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = x\n",
    "        return self.relu(conv + residual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 Pyramid Poolingモジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_channels, pool_sizes, height, width):\n",
    "        super(PyramidPooling, self).__init__()\n",
    "\n",
    "        # forwardで使用する画像サイズ\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        # 各畳み込み層の出力チャネル数\n",
    "        out_channels = int(in_channels / len(pool_sizes))\n",
    "\n",
    "        # 各畳み込み層を作成\n",
    "        # この実装方法は愚直すぎてfor文で書きたいところですが、分かりやすさを優先しています\n",
    "        # pool_sizes: [6, 3, 2, 1]\n",
    "        self.avpool_1 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_2 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[1])\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_3 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[2])\n",
    "        self.cbr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_4 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[3])\n",
    "        self.cbr_4 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.cbr_1(self.avpool_1(x))\n",
    "        out1 = F.interpolate(out1, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out2 = self.cbr_2(self.avpool_2(x))\n",
    "        out2 = F.interpolate(out2, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out3 = self.cbr_3(self.avpool_3(x))\n",
    "        out3 = F.interpolate(out3, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out4 = self.cbr_4(self.avpool_4(x))\n",
    "        out4 = F.interpolate(out4, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        # 最終的に結合させる、dim=1でチャネル数の次元で結合\n",
    "        output = torch.cat([x, out1, out2, out3, out4], dim=1)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Decoder、AuxLossモジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodePSPFeature(nn.Module):\n",
    "    def __init__(self, height, width, n_classes):\n",
    "        super(DecodePSPFeature, self).__init__()\n",
    "\n",
    "        # forwardで使用する画像サイズ\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNormRelu(\n",
    "            in_channels=4096, out_channels=512, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxiliaryPSPlayers(nn.Module):\n",
    "    def __init__(self, in_channels, height, width, n_classes):\n",
    "        super(AuxiliaryPSPlayers, self).__init__()\n",
    "\n",
    "        # forwardで使用する画像サイズ\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNormRelu(\n",
    "            in_channels=in_channels, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSPNet(\n",
       "  (feature_conv): FeatureMap_convolution(\n",
       "    (cbnr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (feature_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block5): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block6): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pyramid_pooling): PyramidPooling(\n",
       "    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n",
       "    (cbr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n",
       "    (cbr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n",
       "    (cbr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n",
       "    (cbr_4): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decode_feature): DecodePSPFeature(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux): AuxiliaryPSPlayers(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの定義\n",
    "net = PSPNet(n_classes=21)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[ 2.9052e-01,  3.9124e-01,  4.9195e-01,  ...,  4.9541e-01,\n",
      "            4.5015e-01,  4.0489e-01],\n",
      "          [ 2.3021e-01,  3.2891e-01,  4.2761e-01,  ...,  4.4488e-01,\n",
      "            3.9858e-01,  3.5228e-01],\n",
      "          [ 1.6991e-01,  2.6659e-01,  3.6327e-01,  ...,  3.9436e-01,\n",
      "            3.4702e-01,  2.9967e-01],\n",
      "          ...,\n",
      "          [ 2.7195e-01,  2.7504e-01,  2.7812e-01,  ..., -4.4794e-01,\n",
      "           -5.0295e-01, -5.5796e-01],\n",
      "          [ 2.2439e-01,  2.2785e-01,  2.3130e-01,  ..., -4.5710e-01,\n",
      "           -5.1340e-01, -5.6969e-01],\n",
      "          [ 1.7683e-01,  1.8066e-01,  1.8449e-01,  ..., -4.6627e-01,\n",
      "           -5.2384e-01, -5.8142e-01]],\n",
      "\n",
      "         [[-1.2074e-02,  3.8316e-03,  1.9737e-02,  ...,  6.3389e-01,\n",
      "            6.3047e-01,  6.2705e-01],\n",
      "          [-3.5711e-02, -1.9308e-02, -2.9055e-03,  ...,  5.9049e-01,\n",
      "            5.8689e-01,  5.8328e-01],\n",
      "          [-5.9349e-02, -4.2448e-02, -2.5548e-02,  ...,  5.4710e-01,\n",
      "            5.4331e-01,  5.3952e-01],\n",
      "          ...,\n",
      "          [-7.0551e-02, -3.8473e-02, -6.3961e-03,  ..., -9.6886e-02,\n",
      "           -7.1486e-02, -4.6085e-02],\n",
      "          [-1.0290e-01, -6.3085e-02, -2.3271e-02,  ..., -7.0765e-02,\n",
      "           -3.6790e-02, -2.8156e-03],\n",
      "          [-1.3525e-01, -8.7697e-02, -4.0146e-02,  ..., -4.4645e-02,\n",
      "           -2.0953e-03,  4.0454e-02]],\n",
      "\n",
      "         [[ 1.2688e-01,  1.7780e-01,  2.2873e-01,  ...,  3.5624e-01,\n",
      "            3.4975e-01,  3.4325e-01],\n",
      "          [ 8.1660e-02,  1.2785e-01,  1.7405e-01,  ...,  3.5168e-01,\n",
      "            3.4371e-01,  3.3575e-01],\n",
      "          [ 3.6438e-02,  7.7903e-02,  1.1937e-01,  ...,  3.4711e-01,\n",
      "            3.3768e-01,  3.2825e-01],\n",
      "          ...,\n",
      "          [ 1.6637e-01,  2.0994e-01,  2.5350e-01,  ...,  4.1675e-01,\n",
      "            4.3665e-01,  4.5655e-01],\n",
      "          [ 1.6276e-01,  2.0483e-01,  2.4690e-01,  ...,  4.0825e-01,\n",
      "            4.3352e-01,  4.5880e-01],\n",
      "          [ 1.5914e-01,  1.9972e-01,  2.4030e-01,  ...,  3.9976e-01,\n",
      "            4.3040e-01,  4.6105e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0505e-01,  1.3539e-01,  6.5729e-02,  ..., -2.3182e-02,\n",
      "           -7.0511e-03,  9.0803e-03],\n",
      "          [ 1.2420e-01,  6.1815e-02, -5.7075e-04,  ..., -1.6308e-02,\n",
      "           -4.1134e-03,  8.0812e-03],\n",
      "          [ 4.3350e-02, -1.1760e-02, -6.6871e-02,  ..., -9.4334e-03,\n",
      "           -1.1757e-03,  7.0820e-03],\n",
      "          ...,\n",
      "          [ 1.7193e-01,  7.7412e-02, -1.7102e-02,  ...,  1.9106e-02,\n",
      "            4.8740e-02,  7.8375e-02],\n",
      "          [ 1.7791e-01,  9.0883e-02,  3.8509e-03,  ...,  4.1120e-02,\n",
      "            7.2522e-02,  1.0392e-01],\n",
      "          [ 1.8390e-01,  1.0435e-01,  2.4804e-02,  ...,  6.3134e-02,\n",
      "            9.6303e-02,  1.2947e-01]],\n",
      "\n",
      "         [[ 3.9521e-02,  3.1753e-02,  2.3985e-02,  ...,  3.6223e-01,\n",
      "            4.2368e-01,  4.8512e-01],\n",
      "          [ 9.6876e-03, -2.4280e-03, -1.4544e-02,  ...,  3.2871e-01,\n",
      "            3.9001e-01,  4.5130e-01],\n",
      "          [-2.0146e-02, -3.6609e-02, -5.3072e-02,  ...,  2.9518e-01,\n",
      "            3.5633e-01,  4.1749e-01],\n",
      "          ...,\n",
      "          [-8.0603e-02, -1.3012e-01, -1.7964e-01,  ...,  5.8700e-02,\n",
      "            5.4333e-02,  4.9966e-02],\n",
      "          [-7.9417e-02, -1.2761e-01, -1.7579e-01,  ...,  3.1698e-02,\n",
      "            3.3942e-02,  3.6187e-02],\n",
      "          [-7.8231e-02, -1.2509e-01, -1.7195e-01,  ...,  4.6955e-03,\n",
      "            1.3552e-02,  2.2408e-02]],\n",
      "\n",
      "         [[-4.6626e-02, -8.5559e-02, -1.2449e-01,  ..., -4.3553e-01,\n",
      "           -4.3871e-01, -4.4188e-01],\n",
      "          [-8.9495e-02, -1.1748e-01, -1.4547e-01,  ..., -3.9680e-01,\n",
      "           -4.0106e-01, -4.0532e-01],\n",
      "          [-1.3236e-01, -1.4941e-01, -1.6645e-01,  ..., -3.5808e-01,\n",
      "           -3.6342e-01, -3.6876e-01],\n",
      "          ...,\n",
      "          [-4.9685e-02, -5.0136e-02, -5.0587e-02,  ...,  2.9587e-01,\n",
      "            3.0705e-01,  3.1824e-01],\n",
      "          [-4.7041e-03, -1.0960e-03,  2.5122e-03,  ...,  3.0458e-01,\n",
      "            3.1500e-01,  3.2542e-01],\n",
      "          [ 4.0277e-02,  4.7944e-02,  5.5612e-02,  ...,  3.1329e-01,\n",
      "            3.2295e-01,  3.3261e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.5318e-02, -3.4980e-02, -3.4642e-02,  ...,  3.5859e-01,\n",
      "            3.5443e-01,  3.5026e-01],\n",
      "          [-1.1195e-02, -9.8469e-03, -8.4987e-03,  ...,  2.9157e-01,\n",
      "            2.8255e-01,  2.7353e-01],\n",
      "          [ 1.2927e-02,  1.5286e-02,  1.7644e-02,  ...,  2.2454e-01,\n",
      "            2.1067e-01,  1.9680e-01],\n",
      "          ...,\n",
      "          [ 1.5449e-01,  1.7532e-01,  1.9616e-01,  ..., -4.0419e-01,\n",
      "           -3.8277e-01, -3.6136e-01],\n",
      "          [ 1.2843e-01,  1.5088e-01,  1.7332e-01,  ..., -3.7249e-01,\n",
      "           -3.3960e-01, -3.0670e-01],\n",
      "          [ 1.0238e-01,  1.2643e-01,  1.5049e-01,  ..., -3.4080e-01,\n",
      "           -2.9642e-01, -2.5204e-01]],\n",
      "\n",
      "         [[ 8.0007e-02,  3.9064e-02, -1.8778e-03,  ...,  2.7973e-01,\n",
      "            3.0109e-01,  3.2246e-01],\n",
      "          [ 6.7839e-02,  3.0692e-02, -6.4541e-03,  ...,  2.5480e-01,\n",
      "            2.7053e-01,  2.8627e-01],\n",
      "          [ 5.5671e-02,  2.2320e-02, -1.1030e-02,  ...,  2.2986e-01,\n",
      "            2.3997e-01,  2.5007e-01],\n",
      "          ...,\n",
      "          [ 9.6556e-02,  1.0179e-01,  1.0703e-01,  ..., -1.7599e-01,\n",
      "           -1.8713e-01, -1.9826e-01],\n",
      "          [ 1.0093e-01,  1.1216e-01,  1.2338e-01,  ..., -1.9416e-01,\n",
      "           -2.1453e-01, -2.3490e-01],\n",
      "          [ 1.0531e-01,  1.2252e-01,  1.3973e-01,  ..., -2.1232e-01,\n",
      "           -2.4193e-01, -2.7154e-01]],\n",
      "\n",
      "         [[ 4.9186e-01,  4.9572e-01,  4.9958e-01,  ...,  4.3356e-01,\n",
      "            4.7107e-01,  5.0857e-01],\n",
      "          [ 4.6275e-01,  4.5970e-01,  4.5665e-01,  ...,  4.2018e-01,\n",
      "            4.5762e-01,  4.9505e-01],\n",
      "          [ 4.3365e-01,  4.2369e-01,  4.1373e-01,  ...,  4.0680e-01,\n",
      "            4.4417e-01,  4.8154e-01],\n",
      "          ...,\n",
      "          [ 2.7190e-01,  2.9369e-01,  3.1548e-01,  ...,  4.9133e-01,\n",
      "            5.2595e-01,  5.6056e-01],\n",
      "          [ 3.1599e-01,  3.3075e-01,  3.4551e-01,  ...,  4.9999e-01,\n",
      "            5.2162e-01,  5.4324e-01],\n",
      "          [ 3.6008e-01,  3.6780e-01,  3.7553e-01,  ...,  5.0866e-01,\n",
      "            5.1729e-01,  5.2592e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1129e-01,  2.7227e-01,  2.3325e-01,  ...,  8.8428e-02,\n",
      "            9.5797e-02,  1.0317e-01],\n",
      "          [ 2.6480e-01,  2.3084e-01,  1.9688e-01,  ...,  1.0412e-01,\n",
      "            1.1243e-01,  1.2074e-01],\n",
      "          [ 2.1831e-01,  1.8941e-01,  1.6051e-01,  ...,  1.1981e-01,\n",
      "            1.2906e-01,  1.3831e-01],\n",
      "          ...,\n",
      "          [ 2.9576e-01,  2.5031e-01,  2.0485e-01,  ...,  5.7424e-01,\n",
      "            6.0730e-01,  6.4035e-01],\n",
      "          [ 3.5434e-01,  2.9781e-01,  2.4127e-01,  ...,  6.0717e-01,\n",
      "            6.3788e-01,  6.6858e-01],\n",
      "          [ 4.1292e-01,  3.4531e-01,  2.7770e-01,  ...,  6.4011e-01,\n",
      "            6.6846e-01,  6.9681e-01]],\n",
      "\n",
      "         [[ 1.9788e-01,  2.3367e-01,  2.6946e-01,  ...,  6.3176e-01,\n",
      "            6.0004e-01,  5.6832e-01],\n",
      "          [ 2.1077e-01,  2.4096e-01,  2.7116e-01,  ...,  5.9444e-01,\n",
      "            5.6716e-01,  5.3988e-01],\n",
      "          [ 2.2366e-01,  2.4826e-01,  2.7285e-01,  ...,  5.5712e-01,\n",
      "            5.3428e-01,  5.1144e-01],\n",
      "          ...,\n",
      "          [-9.0762e-02, -1.0612e-01, -1.2149e-01,  ...,  2.8874e-01,\n",
      "            2.5879e-01,  2.2884e-01],\n",
      "          [-5.6641e-02, -7.3028e-02, -8.9416e-02,  ...,  3.1800e-01,\n",
      "            2.8912e-01,  2.6024e-01],\n",
      "          [-2.2520e-02, -3.9933e-02, -5.7346e-02,  ...,  3.4726e-01,\n",
      "            3.1945e-01,  2.9163e-01]],\n",
      "\n",
      "         [[-4.1189e-01, -4.1516e-01, -4.1843e-01,  ..., -4.3119e-01,\n",
      "           -4.4699e-01, -4.6280e-01],\n",
      "          [-3.7535e-01, -3.8222e-01, -3.8908e-01,  ..., -3.8145e-01,\n",
      "           -3.9710e-01, -4.1275e-01],\n",
      "          [-3.3881e-01, -3.4927e-01, -3.5974e-01,  ..., -3.3172e-01,\n",
      "           -3.4721e-01, -3.6270e-01],\n",
      "          ...,\n",
      "          [-2.2760e-01, -1.9055e-01, -1.5349e-01,  ...,  2.5236e-01,\n",
      "            3.2568e-01,  3.9899e-01],\n",
      "          [-1.9574e-01, -1.6286e-01, -1.2999e-01,  ...,  2.8016e-01,\n",
      "            3.5183e-01,  4.2351e-01],\n",
      "          [-1.6388e-01, -1.3518e-01, -1.0649e-01,  ...,  3.0796e-01,\n",
      "            3.7799e-01,  4.4803e-01]]]], grad_fn=<UpsampleBilinear2DBackward1>), tensor([[[[-2.6508e-01, -2.7484e-01, -2.8460e-01,  ..., -6.4413e-02,\n",
      "           -5.3567e-02, -4.2722e-02],\n",
      "          [-2.6371e-01, -2.6426e-01, -2.6481e-01,  ..., -7.5594e-02,\n",
      "           -7.3718e-02, -7.1842e-02],\n",
      "          [-2.6234e-01, -2.5368e-01, -2.4502e-01,  ..., -8.6776e-02,\n",
      "           -9.3869e-02, -1.0096e-01],\n",
      "          ...,\n",
      "          [ 3.6496e-01,  3.6250e-01,  3.6005e-01,  ..., -2.5732e-01,\n",
      "           -3.1467e-01, -3.7202e-01],\n",
      "          [ 3.5922e-01,  3.6545e-01,  3.7168e-01,  ..., -2.1860e-01,\n",
      "           -2.7947e-01, -3.4033e-01],\n",
      "          [ 3.5347e-01,  3.6840e-01,  3.8332e-01,  ..., -1.7988e-01,\n",
      "           -2.4426e-01, -3.0865e-01]],\n",
      "\n",
      "         [[ 5.7835e-02, -2.6293e-03, -6.3094e-02,  ..., -3.6466e-01,\n",
      "           -3.9334e-01, -4.2203e-01],\n",
      "          [ 9.7281e-02,  4.2625e-02, -1.2031e-02,  ..., -3.6646e-01,\n",
      "           -3.8949e-01, -4.1251e-01],\n",
      "          [ 1.3673e-01,  8.7879e-02,  3.9032e-02,  ..., -3.6826e-01,\n",
      "           -3.8563e-01, -4.0300e-01],\n",
      "          ...,\n",
      "          [ 1.3530e-01,  9.1201e-02,  4.7104e-02,  ..., -1.5840e-01,\n",
      "           -1.6621e-01, -1.7402e-01],\n",
      "          [ 1.2634e-01,  6.8868e-02,  1.1394e-02,  ..., -1.8313e-01,\n",
      "           -1.8468e-01, -1.8624e-01],\n",
      "          [ 1.1739e-01,  4.6535e-02, -2.4317e-02,  ..., -2.0786e-01,\n",
      "           -2.0316e-01, -1.9846e-01]],\n",
      "\n",
      "         [[ 4.2367e-01,  4.8305e-01,  5.4244e-01,  ...,  6.3072e-01,\n",
      "            6.1057e-01,  5.9042e-01],\n",
      "          [ 4.0174e-01,  4.5492e-01,  5.0809e-01,  ...,  5.7899e-01,\n",
      "            5.6006e-01,  5.4114e-01],\n",
      "          [ 3.7982e-01,  4.2678e-01,  4.7374e-01,  ...,  5.2725e-01,\n",
      "            5.0956e-01,  4.9186e-01],\n",
      "          ...,\n",
      "          [ 2.8120e-01,  2.6598e-01,  2.5076e-01,  ...,  3.1634e-01,\n",
      "            3.1561e-01,  3.1488e-01],\n",
      "          [ 2.3564e-01,  2.3525e-01,  2.3486e-01,  ...,  3.3312e-01,\n",
      "            3.4311e-01,  3.5310e-01],\n",
      "          [ 1.9007e-01,  2.0452e-01,  2.1897e-01,  ...,  3.4989e-01,\n",
      "            3.7061e-01,  3.9132e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1773e-01, -4.1479e-01, -4.1184e-01,  ...,  3.3760e-02,\n",
      "           -3.7344e-02, -1.0845e-01],\n",
      "          [-4.5972e-01, -4.5037e-01, -4.4101e-01,  ...,  6.4679e-02,\n",
      "            3.5565e-03, -5.7565e-02],\n",
      "          [-5.0171e-01, -4.8595e-01, -4.7019e-01,  ...,  9.5597e-02,\n",
      "            4.4457e-02, -6.6830e-03],\n",
      "          ...,\n",
      "          [-1.0040e-01, -6.7191e-02, -3.3985e-02,  ...,  7.8195e-02,\n",
      "            2.9739e-02, -1.8716e-02],\n",
      "          [ 1.9921e-03,  3.2425e-02,  6.2858e-02,  ...,  1.1767e-01,\n",
      "            6.4800e-02,  1.1929e-02],\n",
      "          [ 1.0438e-01,  1.3204e-01,  1.5970e-01,  ...,  1.5715e-01,\n",
      "            9.9861e-02,  4.2575e-02]],\n",
      "\n",
      "         [[-1.1818e-01, -1.1527e-01, -1.1236e-01,  ...,  1.4796e-01,\n",
      "            1.0155e-01,  5.5138e-02],\n",
      "          [-1.2528e-01, -1.2492e-01, -1.2455e-01,  ...,  1.6881e-01,\n",
      "            1.2543e-01,  8.2056e-02],\n",
      "          [-1.3238e-01, -1.3456e-01, -1.3674e-01,  ...,  1.8967e-01,\n",
      "            1.4932e-01,  1.0897e-01],\n",
      "          ...,\n",
      "          [ 4.0268e-01,  3.6437e-01,  3.2606e-01,  ...,  3.5720e-01,\n",
      "            3.0743e-01,  2.5767e-01],\n",
      "          [ 4.1563e-01,  3.8407e-01,  3.5250e-01,  ...,  4.2012e-01,\n",
      "            3.8056e-01,  3.4099e-01],\n",
      "          [ 4.2859e-01,  4.0376e-01,  3.7894e-01,  ...,  4.8305e-01,\n",
      "            4.5368e-01,  4.2432e-01]],\n",
      "\n",
      "         [[-7.5191e-01, -6.2646e-01, -5.0100e-01,  ..., -5.1191e-02,\n",
      "           -4.7326e-02, -4.3462e-02],\n",
      "          [-7.5043e-01, -6.2686e-01, -5.0329e-01,  ..., -6.3071e-02,\n",
      "           -6.4109e-02, -6.5147e-02],\n",
      "          [-7.4895e-01, -6.2726e-01, -5.0558e-01,  ..., -7.4950e-02,\n",
      "           -8.0891e-02, -8.6833e-02],\n",
      "          ...,\n",
      "          [-4.1812e-01, -4.1281e-01, -4.0750e-01,  ..., -3.7477e-02,\n",
      "           -2.0277e-02, -3.0780e-03],\n",
      "          [-3.8142e-01, -3.7243e-01, -3.6343e-01,  ...,  1.5461e-02,\n",
      "            3.8601e-02,  6.1741e-02],\n",
      "          [-3.4473e-01, -3.3205e-01, -3.1937e-01,  ...,  6.8399e-02,\n",
      "            9.7479e-02,  1.2656e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0533e-01,  2.0350e-01,  2.0167e-01,  ..., -2.1573e-01,\n",
      "           -2.6977e-01, -3.2381e-01],\n",
      "          [ 2.3522e-01,  2.3151e-01,  2.2780e-01,  ..., -1.9673e-01,\n",
      "           -2.4243e-01, -2.8812e-01],\n",
      "          [ 2.6511e-01,  2.5952e-01,  2.5393e-01,  ..., -1.7773e-01,\n",
      "           -2.1508e-01, -2.5243e-01],\n",
      "          ...,\n",
      "          [ 2.4853e-01,  2.3094e-01,  2.1336e-01,  ..., -3.7429e-03,\n",
      "           -2.4728e-02, -4.5713e-02],\n",
      "          [ 2.1337e-01,  1.9747e-01,  1.8158e-01,  ...,  2.5115e-02,\n",
      "           -4.4163e-03, -3.3947e-02],\n",
      "          [ 1.7820e-01,  1.6400e-01,  1.4981e-01,  ...,  5.3972e-02,\n",
      "            1.5896e-02, -2.2181e-02]],\n",
      "\n",
      "         [[-4.7290e-02, -6.0902e-02, -7.4514e-02,  ..., -3.2827e-01,\n",
      "           -3.5382e-01, -3.7937e-01],\n",
      "          [-6.5262e-02, -7.1439e-02, -7.7617e-02,  ..., -3.2315e-01,\n",
      "           -3.5013e-01, -3.7710e-01],\n",
      "          [-8.3233e-02, -8.1977e-02, -8.0720e-02,  ..., -3.1803e-01,\n",
      "           -3.4643e-01, -3.7483e-01],\n",
      "          ...,\n",
      "          [-4.5896e-01, -4.3839e-01, -4.1782e-01,  ..., -1.4710e-01,\n",
      "           -1.5877e-01, -1.7044e-01],\n",
      "          [-5.0513e-01, -4.8566e-01, -4.6619e-01,  ..., -1.5167e-01,\n",
      "           -1.6597e-01, -1.8026e-01],\n",
      "          [-5.5130e-01, -5.3293e-01, -5.1456e-01,  ..., -1.5623e-01,\n",
      "           -1.7316e-01, -1.9008e-01]],\n",
      "\n",
      "         [[-1.1924e-01, -7.3419e-02, -2.7598e-02,  ...,  3.1696e-01,\n",
      "            2.0774e-01,  9.8525e-02],\n",
      "          [-7.3175e-02, -3.3035e-02,  7.1050e-03,  ...,  2.6423e-01,\n",
      "            1.6274e-01,  6.1257e-02],\n",
      "          [-2.7109e-02,  7.3496e-03,  4.1808e-02,  ...,  2.1150e-01,\n",
      "            1.1774e-01,  2.3989e-02],\n",
      "          ...,\n",
      "          [ 2.4530e-01,  2.1177e-01,  1.7823e-01,  ...,  2.5133e-01,\n",
      "            2.3672e-01,  2.2211e-01],\n",
      "          [ 3.3212e-01,  2.8703e-01,  2.4194e-01,  ...,  2.8068e-01,\n",
      "            2.6159e-01,  2.4249e-01],\n",
      "          [ 4.1894e-01,  3.6230e-01,  3.0566e-01,  ...,  3.1002e-01,\n",
      "            2.8645e-01,  2.6288e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2976e-01, -2.4207e-01, -1.5438e-01,  ...,  2.9505e-01,\n",
      "            2.9611e-01,  2.9717e-01],\n",
      "          [-2.9941e-01, -2.2050e-01, -1.4159e-01,  ...,  3.0919e-01,\n",
      "            3.1078e-01,  3.1238e-01],\n",
      "          [-2.6907e-01, -1.9894e-01, -1.2880e-01,  ...,  3.2333e-01,\n",
      "            3.2545e-01,  3.2758e-01],\n",
      "          ...,\n",
      "          [ 2.2488e-01,  2.4695e-01,  2.6902e-01,  ...,  2.2533e-01,\n",
      "            2.2340e-01,  2.2147e-01],\n",
      "          [ 2.8288e-01,  3.0714e-01,  3.3140e-01,  ...,  2.6447e-01,\n",
      "            2.6565e-01,  2.6683e-01],\n",
      "          [ 3.4089e-01,  3.6734e-01,  3.9378e-01,  ...,  3.0360e-01,\n",
      "            3.0790e-01,  3.1219e-01]],\n",
      "\n",
      "         [[ 1.5992e-01,  1.6231e-01,  1.6469e-01,  ...,  9.5270e-02,\n",
      "            7.6017e-02,  5.6763e-02],\n",
      "          [ 2.1523e-01,  2.1769e-01,  2.2014e-01,  ...,  1.1308e-01,\n",
      "            9.8810e-02,  8.4541e-02],\n",
      "          [ 2.7054e-01,  2.7307e-01,  2.7559e-01,  ...,  1.3089e-01,\n",
      "            1.2160e-01,  1.1232e-01],\n",
      "          ...,\n",
      "          [ 5.1946e-01,  5.0292e-01,  4.8639e-01,  ...,  6.7348e-01,\n",
      "            6.5907e-01,  6.4465e-01],\n",
      "          [ 5.9042e-01,  5.7740e-01,  5.6439e-01,  ...,  7.4594e-01,\n",
      "            7.4099e-01,  7.3603e-01],\n",
      "          [ 6.6139e-01,  6.5188e-01,  6.4238e-01,  ...,  8.1840e-01,\n",
      "            8.2291e-01,  8.2742e-01]],\n",
      "\n",
      "         [[-1.8186e-01, -1.5191e-01, -1.2195e-01,  ..., -1.5310e-02,\n",
      "           -4.2386e-03,  6.8325e-03],\n",
      "          [-1.7858e-01, -1.4638e-01, -1.1419e-01,  ..., -1.3918e-02,\n",
      "            1.1824e-05,  1.3941e-02],\n",
      "          [-1.7529e-01, -1.4086e-01, -1.0644e-01,  ..., -1.2525e-02,\n",
      "            4.2622e-03,  2.1050e-02],\n",
      "          ...,\n",
      "          [-3.1615e-01, -2.9955e-01, -2.8294e-01,  ...,  1.4060e-01,\n",
      "            1.6123e-01,  1.8186e-01],\n",
      "          [-2.9696e-01, -2.8491e-01, -2.7286e-01,  ...,  1.2118e-01,\n",
      "            1.3763e-01,  1.5408e-01],\n",
      "          [-2.7777e-01, -2.7028e-01, -2.6279e-01,  ...,  1.0175e-01,\n",
      "            1.1403e-01,  1.2630e-01]]]], grad_fn=<UpsampleBilinear2DBackward1>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    }
   ],
   "source": [
    "# ダミーデータの作成\n",
    "batch_size = 2\n",
    "dummy_img = torch.rand(batch_size, 3, 475, 475)\n",
    "\n",
    "# 計算\n",
    "outputs = net(dummy_img)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
